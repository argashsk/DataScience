{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2023-04-26T08:52:02.596101Z","iopub.execute_input":"2023-04-26T08:52:02.596565Z","iopub.status.idle":"2023-04-26T08:52:05.655419Z","shell.execute_reply.started":"2023-04-26T08:52:02.596520Z","shell.execute_reply":"2023-04-26T08:52:05.654015Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df= pd.read_csv(\"/kaggle/input/creditcardfraud/creditcard.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-04-26T08:52:05.658128Z","iopub.execute_input":"2023-04-26T08:52:05.659019Z","iopub.status.idle":"2023-04-26T08:52:10.979089Z","shell.execute_reply.started":"2023-04-26T08:52:05.658960Z","shell.execute_reply":"2023-04-26T08:52:10.977202Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Explratory Data Analysis","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(15)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T08:52:10.980826Z","iopub.execute_input":"2023-04-26T08:52:10.982589Z","iopub.status.idle":"2023-04-26T08:52:11.050148Z","shell.execute_reply.started":"2023-04-26T08:52:10.982532Z","shell.execute_reply":"2023-04-26T08:52:11.048713Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"    Time        V1        V2        V3        V4        V5        V6  \\\n0    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n1    0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n2    1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n3    1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n4    2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n5    2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728   \n6    4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708   \n7    7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118   \n8    7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818   \n9    9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761   \n10  10.0  1.449044 -1.176339  0.913860 -1.375667 -1.971383 -0.629152   \n11  10.0  0.384978  0.616109 -0.874300 -0.094019  2.924584  3.317027   \n12  10.0  1.249999 -1.221637  0.383930 -1.234899 -1.485419 -0.753230   \n13  11.0  1.069374  0.287722  0.828613  2.712520 -0.178398  0.337544   \n14  12.0 -2.791855 -0.327771  1.641750  1.767473 -0.136588  0.807596   \n\n          V7        V8        V9  ...       V21       V22       V23       V24  \\\n0   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n1  -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n2   0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n3   0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575   \n4   0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267   \n5   0.476201  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427   \n6  -0.005159  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055   \n7   1.120631 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709   \n8   0.370145  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592   \n9   0.651583  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050   \n10 -1.423236  0.048456 -1.720408  ... -0.009302  0.313894  0.027740  0.500512   \n11  0.470455  0.538247 -0.558895  ...  0.049924  0.238422  0.009130  0.996710   \n12 -0.689405 -0.227487 -2.094011  ... -0.231809 -0.483285  0.084668  0.392831   \n13 -0.096717  0.115982 -0.221083  ... -0.036876  0.074412 -0.071407  0.104744   \n14 -0.422911 -1.907107  0.755713  ...  1.151663  0.222182  1.020586  0.028317   \n\n         V25       V26       V27       V28  Amount  Class  \n0   0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n1   0.167170  0.125895 -0.008983  0.014724    2.69      0  \n2  -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n3   0.647376 -0.221929  0.062723  0.061458  123.50      0  \n4  -0.206010  0.502292  0.219422  0.215153   69.99      0  \n5  -0.232794  0.105915  0.253844  0.081080    3.67      0  \n6   0.750137 -0.257237  0.034507  0.005168    4.99      0  \n7  -0.415267 -0.051634 -1.206921 -1.085339   40.80      0  \n8   0.373205 -0.384157  0.011747  0.142404   93.20      0  \n9  -0.069733  0.094199  0.246219  0.083076    3.68      0  \n10  0.251367 -0.129478  0.042850  0.016253    7.80      0  \n11 -0.767315 -0.492208  0.042472 -0.054337    9.99      0  \n12  0.161135 -0.354990  0.026416  0.042422  121.50      0  \n13  0.548265  0.104094  0.021491  0.021293   27.50      0  \n14 -0.232746 -0.235557 -0.164778 -0.030154   58.80      0  \n\n[15 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2.0</td>\n      <td>-0.425966</td>\n      <td>0.960523</td>\n      <td>1.141109</td>\n      <td>-0.168252</td>\n      <td>0.420987</td>\n      <td>-0.029728</td>\n      <td>0.476201</td>\n      <td>0.260314</td>\n      <td>-0.568671</td>\n      <td>...</td>\n      <td>-0.208254</td>\n      <td>-0.559825</td>\n      <td>-0.026398</td>\n      <td>-0.371427</td>\n      <td>-0.232794</td>\n      <td>0.105915</td>\n      <td>0.253844</td>\n      <td>0.081080</td>\n      <td>3.67</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4.0</td>\n      <td>1.229658</td>\n      <td>0.141004</td>\n      <td>0.045371</td>\n      <td>1.202613</td>\n      <td>0.191881</td>\n      <td>0.272708</td>\n      <td>-0.005159</td>\n      <td>0.081213</td>\n      <td>0.464960</td>\n      <td>...</td>\n      <td>-0.167716</td>\n      <td>-0.270710</td>\n      <td>-0.154104</td>\n      <td>-0.780055</td>\n      <td>0.750137</td>\n      <td>-0.257237</td>\n      <td>0.034507</td>\n      <td>0.005168</td>\n      <td>4.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7.0</td>\n      <td>-0.644269</td>\n      <td>1.417964</td>\n      <td>1.074380</td>\n      <td>-0.492199</td>\n      <td>0.948934</td>\n      <td>0.428118</td>\n      <td>1.120631</td>\n      <td>-3.807864</td>\n      <td>0.615375</td>\n      <td>...</td>\n      <td>1.943465</td>\n      <td>-1.015455</td>\n      <td>0.057504</td>\n      <td>-0.649709</td>\n      <td>-0.415267</td>\n      <td>-0.051634</td>\n      <td>-1.206921</td>\n      <td>-1.085339</td>\n      <td>40.80</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7.0</td>\n      <td>-0.894286</td>\n      <td>0.286157</td>\n      <td>-0.113192</td>\n      <td>-0.271526</td>\n      <td>2.669599</td>\n      <td>3.721818</td>\n      <td>0.370145</td>\n      <td>0.851084</td>\n      <td>-0.392048</td>\n      <td>...</td>\n      <td>-0.073425</td>\n      <td>-0.268092</td>\n      <td>-0.204233</td>\n      <td>1.011592</td>\n      <td>0.373205</td>\n      <td>-0.384157</td>\n      <td>0.011747</td>\n      <td>0.142404</td>\n      <td>93.20</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9.0</td>\n      <td>-0.338262</td>\n      <td>1.119593</td>\n      <td>1.044367</td>\n      <td>-0.222187</td>\n      <td>0.499361</td>\n      <td>-0.246761</td>\n      <td>0.651583</td>\n      <td>0.069539</td>\n      <td>-0.736727</td>\n      <td>...</td>\n      <td>-0.246914</td>\n      <td>-0.633753</td>\n      <td>-0.120794</td>\n      <td>-0.385050</td>\n      <td>-0.069733</td>\n      <td>0.094199</td>\n      <td>0.246219</td>\n      <td>0.083076</td>\n      <td>3.68</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10.0</td>\n      <td>1.449044</td>\n      <td>-1.176339</td>\n      <td>0.913860</td>\n      <td>-1.375667</td>\n      <td>-1.971383</td>\n      <td>-0.629152</td>\n      <td>-1.423236</td>\n      <td>0.048456</td>\n      <td>-1.720408</td>\n      <td>...</td>\n      <td>-0.009302</td>\n      <td>0.313894</td>\n      <td>0.027740</td>\n      <td>0.500512</td>\n      <td>0.251367</td>\n      <td>-0.129478</td>\n      <td>0.042850</td>\n      <td>0.016253</td>\n      <td>7.80</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10.0</td>\n      <td>0.384978</td>\n      <td>0.616109</td>\n      <td>-0.874300</td>\n      <td>-0.094019</td>\n      <td>2.924584</td>\n      <td>3.317027</td>\n      <td>0.470455</td>\n      <td>0.538247</td>\n      <td>-0.558895</td>\n      <td>...</td>\n      <td>0.049924</td>\n      <td>0.238422</td>\n      <td>0.009130</td>\n      <td>0.996710</td>\n      <td>-0.767315</td>\n      <td>-0.492208</td>\n      <td>0.042472</td>\n      <td>-0.054337</td>\n      <td>9.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>10.0</td>\n      <td>1.249999</td>\n      <td>-1.221637</td>\n      <td>0.383930</td>\n      <td>-1.234899</td>\n      <td>-1.485419</td>\n      <td>-0.753230</td>\n      <td>-0.689405</td>\n      <td>-0.227487</td>\n      <td>-2.094011</td>\n      <td>...</td>\n      <td>-0.231809</td>\n      <td>-0.483285</td>\n      <td>0.084668</td>\n      <td>0.392831</td>\n      <td>0.161135</td>\n      <td>-0.354990</td>\n      <td>0.026416</td>\n      <td>0.042422</td>\n      <td>121.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>11.0</td>\n      <td>1.069374</td>\n      <td>0.287722</td>\n      <td>0.828613</td>\n      <td>2.712520</td>\n      <td>-0.178398</td>\n      <td>0.337544</td>\n      <td>-0.096717</td>\n      <td>0.115982</td>\n      <td>-0.221083</td>\n      <td>...</td>\n      <td>-0.036876</td>\n      <td>0.074412</td>\n      <td>-0.071407</td>\n      <td>0.104744</td>\n      <td>0.548265</td>\n      <td>0.104094</td>\n      <td>0.021491</td>\n      <td>0.021293</td>\n      <td>27.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>12.0</td>\n      <td>-2.791855</td>\n      <td>-0.327771</td>\n      <td>1.641750</td>\n      <td>1.767473</td>\n      <td>-0.136588</td>\n      <td>0.807596</td>\n      <td>-0.422911</td>\n      <td>-1.907107</td>\n      <td>0.755713</td>\n      <td>...</td>\n      <td>1.151663</td>\n      <td>0.222182</td>\n      <td>1.020586</td>\n      <td>0.028317</td>\n      <td>-0.232746</td>\n      <td>-0.235557</td>\n      <td>-0.164778</td>\n      <td>-0.030154</td>\n      <td>58.80</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>15 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data1 = (df[\"Class\"] == 1).sum()\nprint(data1)\ndata0 = (df[\"Class\"] == 0).sum()\nprint(data0)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T08:52:11.053571Z","iopub.execute_input":"2023-04-26T08:52:11.054537Z","iopub.status.idle":"2023-04-26T08:52:11.071669Z","shell.execute_reply.started":"2023-04-26T08:52:11.054374Z","shell.execute_reply":"2023-04-26T08:52:11.069316Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"492\n284315\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data Preprocessing","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U imbalanced-learn\n!pip install -U imblearn","metadata":{"execution":{"iopub.status.busy":"2023-04-26T08:52:11.073752Z","iopub.execute_input":"2023-04-26T08:52:11.074291Z","iopub.status.idle":"2023-04-26T08:52:36.212648Z","shell.execute_reply.started":"2023-04-26T08:52:11.074237Z","shell.execute_reply":"2023-04-26T08:52:36.211320Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.7/site-packages (0.10.1)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.7.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (3.1.0)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.21.6)\nRequirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.0.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting imblearn\n  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\nRequirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.7/site-packages (from imblearn) (0.10.1)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.21.6)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.2.0)\nRequirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.0.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.7.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (3.1.0)\nInstalling collected packages: imblearn\nSuccessfully installed imblearn-0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"X=df.iloc[:,:-1]\ny=df[\"Class\"]","metadata":{"execution":{"iopub.status.busy":"2023-04-26T08:52:36.214497Z","iopub.execute_input":"2023-04-26T08:52:36.215383Z","iopub.status.idle":"2023-04-26T08:52:36.251236Z","shell.execute_reply.started":"2023-04-26T08:52:36.215336Z","shell.execute_reply":"2023-04-26T08:52:36.249726Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nX_train_rus, X_test, y_train_rus, y_test  = train_test_split(X, y, test_size=0.1)\nrus = RandomUnderSampler()\n\nX_train_rus, y_train_rus = rus.fit_resample(X_train_rus, y_train_rus)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T08:52:36.253291Z","iopub.execute_input":"2023-04-26T08:52:36.254211Z","iopub.status.idle":"2023-04-26T08:52:36.826858Z","shell.execute_reply.started":"2023-04-26T08:52:36.254154Z","shell.execute_reply":"2023-04-26T08:52:36.825513Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Machine Learning Modeling","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier()\nrus_model_rf = rf.fit(X_train_rus,y_train_rus)\nrus_predict = rus_model_rf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T08:52:36.829809Z","iopub.execute_input":"2023-04-26T08:52:36.830895Z","iopub.status.idle":"2023-04-26T08:52:37.468848Z","shell.execute_reply.started":"2023-04-26T08:52:36.830846Z","shell.execute_reply":"2023-04-26T08:52:37.467455Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(classification_report(rus_predict,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-04-26T08:52:37.470489Z","iopub.execute_input":"2023-04-26T08:52:37.471272Z","iopub.status.idle":"2023-04-26T08:52:37.508128Z","shell.execute_reply.started":"2023-04-26T08:52:37.471219Z","shell.execute_reply":"2023-04-26T08:52:37.506440Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99     28006\n           1       0.89      0.09      0.16       475\n\n    accuracy                           0.98     28481\n   macro avg       0.94      0.54      0.58     28481\nweighted avg       0.98      0.98      0.98     28481\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Pisahkan data menjadi training dan validation set\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Tentukan model yang akan digunakan\nmodel = RandomForestClassifier()\n\n# Tentukan parameter yang akan dioptimalkan\nparams = {\n    'max_depth': [2, 5, 7],\n    'min_samples_leaf': [1, 5, 10]\n}\n\n# Buat fungsi evaluasi berdasarkan recall\ndef recall_eval(y_true, y_pred):\n    report = classification_report(y_true, y_pred)\n    recall = float(report.split()[-4])\n    return recall\n\n# Gunakan GridSearchCV untuk mencari parameter terbaik\ngrid = GridSearchCV(model, params, cv=5, scoring='recall')\ngrid.fit(X_train, y_train)\n\n# Cetak parameter terbaik\nprint(grid.best_params_)\n\n# Uji model terbaik pada data validasi\ny_pred = grid.predict(X_val)\nprint(classification_report(y_val, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-26T08:52:37.513002Z","iopub.execute_input":"2023-04-26T08:52:37.513437Z","iopub.status.idle":"2023-04-26T09:44:20.831826Z","shell.execute_reply.started":"2023-04-26T08:52:37.513397Z","shell.execute_reply":"2023-04-26T09:44:20.830193Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"{'max_depth': 7, 'min_samples_leaf': 1}\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     56864\n           1       0.99      0.74      0.85        98\n\n    accuracy                           1.00     56962\n   macro avg       0.99      0.87      0.92     56962\nweighted avg       1.00      1.00      1.00     56962\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}